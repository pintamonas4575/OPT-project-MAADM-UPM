{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1 - Dilema del Prisionero Iterado\n",
    "\n",
    "## Introducción\n",
    "\n",
    "La *Teoría de Juegos* es una rama de las matemáticas que estudia la interacción entre individuos racionales. Para su estudio, es habitual que se utilicen *juegos* o *dilemas* en los que los agentes implicados puedan escoger entre varias *acciones*. El resultado del juego dependerá de la acción propia y las de los oponentes. Un ejemplo muy conocido es el juego de *piedra, papel y tijera*.\n",
    "\n",
    "Probablemente el *juego* o *dilema* más estudiado dentro de la Teoría de Juegos es el [**Dilema del Prisionero**](https://en.wikipedia.org/wiki/Prisoner%27s_dilemma). En este dilema, los jugadores tienen dos opciones: cooperar (C) o desertar (D). A la siguiente matriz se la conoce como *matriz de pagos* (*payoff matrix*), y es una forma compacta de representar un juego: por filas se representa a un jugador, y por columnas al otro.\n",
    "\n",
    "<center>\n",
    "\n",
    "|      |  C    |  D    |\n",
    "|------|-------|-------|\n",
    "|   **C**  | 2, 2  | -1, 3 |\n",
    "|   **D**  | 3, -1 |  0, 0 |\n",
    "\n",
    "</center>\n",
    "\n",
    "Las celdas interiores de la matriz establecen los pagos que se lleva cada jugador. El primer número de la tupla es el pago al jugador *fila*, y el segundo número el pago al jugador *columna*. Por ejemplo, si el jugador *fila* deserta (D) y el jugador *columna* coopera (C), el primero se llevará 3 puntos y el segundo *-1*. En verdad, los valores de la tabla no son *puntos*, es una medida sin dimensiones cuya única función es permitirnos comparar resultados. De hecho, no existe un *único* dilema del prisionero: se pueden modificar los valores anteriores libremente, siempre que se mantengan las relaciones ordinales entre ellos.\n",
    "\n",
    "Para juegos simétricos como el dilema del prisionero, suele ser más conveniente utilizar la *matriz de pagos simplificada*\n",
    "\n",
    "<center>\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "2 & -1 \\\\\n",
    "3 & 0 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "No olvides que los jugadores del dilema del prisionero son jugadores racionales. Además, **el objetivo no es *ganar* al rival, sino maximizar el beneficio personal**. Estas dos premisas son las hipótesis sobre las que se sustenta todo lo que viene a continuación.\n",
    "\n",
    "Cuando se juega al dilema del prisionero una única vez, la estrategia óptima es la de desertar (ejercicio: reflexiona sobre el por qué). Sin embargo, la complejidad surge cuando los jugadores se enfrentan repetidamente con el mismo oponente, ya que sus acciones actuales influirán en su reputación a largo plazo. Esta variante se conoce como el **Dilema del Prisionero Iterado** y ha sido objeto de profundo estudio en la literatura científica. A pesar de que John von Neumann fue el primero en plantear este dilema, Robert Axelrod ha destacado como uno de los científicos más influyentes en su análisis.\n",
    "\n",
    "Axelrod planteó varios \"campeonatos computacionales\", en los que los participantes debían proponer una estrategia para jugar al DPI. Luego Axelrod enfrentó todas las estrategias y vio cuáles eran las que mejor funcionaban. Una *estrategia* para jugar al DPI es un conjunto de instrucciones inequívocas que, a partir del histórico de movimientos de ambos jugadores, dice cuál debe ser el siguiente movimiento. Por ejemplo, lo siguiente sería una estrategia: \"comienzo cooperando, luego deserto dos veces, y a partir de la cuarta ronda coopero siempre\". Algunas de estas estrategias se han hecho famosas por ser exitosas o por aparece con frecuencia en la literatura.\n",
    "\n",
    "Axelrod comenzó estudiando torneos *normales* (llamados *de enfrentamiento directo*), donde cada participante (estrategia) es enfrentado contra cada uno de los demás, sumando los resultados obtenidos en cada interacción, y estableciendo un ranking al final del campeonato. También estudió los llamados *torneos evolutivos*. En ellos cada estrategia parte con un número de individuos representantes que juegan siempre esa estrategia. Tras enfrentar todos los individuos contra todos, se elimina de la población los que peor resultado han obtenido, sustituyéndolos por los más exitosos. Este proceso se repite varias veces, dando lugar (en muchos casos) a que una estrategia coloniza a la población completa: se encuentra la estrategia óptima. En escenarios más avanzados, se permite también la evolución de las estrategias a lo largo de las generaciones, mediante mecanismos de mutación y cruce (selección natural).\n",
    "\n",
    "Las metaheurísticas son técnicas de optimización confeccionadas para casos particulares, complejos y dinámicos. El DPI evolutivo es ejemplo tangible de esta técnica. En este problema, múltiples soluciones compiten y evolucionan hacia la optimización de un objetivo dado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción de la práctica\n",
    "\n",
    "**¡Importante!** Comienza jugando al juego de Nicky Case llamado *The evolution of trust* (~30min). Es un buen resumen de los conceptos previos que necesitas saber sobre el DPI antes de comenzar la práctica:\n",
    "<center>\n",
    "\n",
    "[<img src=\"https://ncase.me/img/trust.png\" alt=\"The evolution of trust: https://ncase.me/trust/\" width=\"400\">](https://ncase.me/trust/)\n",
    "\n",
    "https://ncase.me/trust/\n",
    "</center>\n",
    "Unas aclaraciones sobre el juego: en ocasiones, el autor utiliza una nomenclatura que no es habitual en la literatura del DPI. Por evitar confusiones:\n",
    "\n",
    " - Las acciones posibles en el dilema las llamaremos Cooperar (*Cooperate*) y Desertar (*Defect*), y no *cheat*.\n",
    " - La estrategia que repite el último movimiento del rival se conoce ampliamente como *Tit-For-Tat*, y no *Copycat*.\n",
    "\n",
    "La práctica tiene dos partes:\n",
    " - **Parte 1**: Montar la estructura computacional que permita simular torneos del DPI.\n",
    " - **Parte 2**: Diseñar una estrategia, que se enfrentará a las de tus compañeros en un torneo de tres fases descrito a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Sofware para el estudio del DPI\n",
    "\n",
    "El primer objetivo es crear un sofware que permita simular torneos del DPI. En concreto, el software debe cumplir los siguientes requisitos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Para el torneo de enfrentamiento directo, las entradas al programa deben ser:\n",
    "   - ```all_players```: lista o tupla de jugadores que van a participar en el campeonato (con información sobre sus estrategias).\n",
    "   - ```dilemma```: objeto para definir el dilema del prisionero jugado (en particular, deberá contener la información de la correspondiente matriz de pagos, que es la mostrada arriba).\n",
    "   - ```n_rounds```: número de rondas por cada enfrentamiento.\n",
    "   - ```error```: probabilidad de error por jugada.\n",
    "   - ```repetitions```: el número de veces que una estrategia va a enfrentarse a otra.\n",
    " - La salida debe ser la información (visual) sobre el resultado del campeonato.\n",
    " - Además, el programa deberá contener al menos las 5 estrategias básicas descritas en el juego de Nicky Case. Igualmente, deberá permitir añadir nuevas estrategias de forma sencilla.\n",
    "\n",
    "Consulta la sección sobre el *módulo evolutivo* para ver las particularidades de esa parte.\n",
    "\n",
    "A continuación se propone una **plantilla de desarrollo** con los módulos/clases que se recomienda implementar para resolver este problema. No es obligatorio seguir esta estructura. Por otro lado, puede ser recomendable organizar el código en un proyecto local en lugar de en *Jupyter* o *Colab*. Si quieres hacerlo, la estructura del proyecto recomendada es la siguiente:\n",
    "\n",
    "```\n",
    " DPI/\n",
    "   ├── dpi/\n",
    "   │   ├── __init__.py\n",
    "   │   ├── dilemma.py  # implementa la lógica del DP jugado, acciones posibles, matriz de pagos, etc\n",
    "   │   ├── player.py  # implementa la definición de \"Jugador\" y en particular, la estrategia\n",
    "   │   ├── game.py  # implementa la dinámica de un juego cara a cara entre dos jugadores\n",
    "   │   ├── tournament.py  # implementa la dinámica del torneo general\n",
    "   │   └── evolution.py  # implementa la dinámica del torneo evolutivo\n",
    "   ├── main.py # main del proyecto - si quieres, usa varios 'mains' para testear los distintos módulos\n",
    "   └──...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plantilla de desarrollo\n",
    "\n",
    "Se incluye a continuación una plantilla con los módulos/clases que se recomienda implementar, junto con variables y métodos necesarios. El objetivo es facilitar la tarea de diseñar el código. No es obligatorio seguir esta estructura, pero a falta de mejores ideas, puede ser un buen punto de partida.\n",
    "\n",
    "Para facilitar la tarea de identificar qué métodos faltan por implementar, en todos ellos se ha incluido la excepción ```raise NotImplementedError``` para poner de manifiesto que dicho método debe ser implementado.\n",
    "\n",
    "Se comienza importando librerías. El uso de otras librerías **basicas** también está permitido, siempre que esté justificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El módulo ```dilemma```\n",
    "\n",
    "El primer módulo que se recomienda implementar es el que recoge la información sobre el dilema jugado. Como el DP solo tiene dos acciones posibles (*Cooperate* y *Defect*), por simplicidad crearemos dos variables globales ```C``` y ```D``` asociadas a dos enteros (0 y 1 respectivamente). Representarán estas dos acciones a lo largo de todo el código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0\n",
    "D = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se propone implementar una clase llamada ```Dilemma``` para representar dilemas simétricos 2x2, como el dilema del prisionero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dilemma:\n",
    "\n",
    "    def __init__(self, cc: float, cd: float, dc: float, dd: float):\n",
    "        \"\"\"\n",
    "        Represents a 2x2 symmetric dilemma.\n",
    "\n",
    "        Parameters:\n",
    "            - cc (float): payoff for mutual cooperation\n",
    "            - cd (float): payoff when one cooperates, but the opponent defects\n",
    "            - dc (float): payoff when one defects, and the opponent cooperates\n",
    "            - dd (float): payoff for mutual defection\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def payoff_matrix(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Symmetric pay-off matrix of the dilema\n",
    "\n",
    "        Returns:\n",
    "            - 2x2 np array of the matrix\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def evaluate_result(self, a_1: int, a_2: int) -> tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Given two actions, returns the payoffs of the two players.\n",
    "\n",
    "        Parameters:\n",
    "            - a_1 (int): action of player 1 ('C' or 'D', i.e. '1' or '0')\n",
    "            - a_2 (int): action of player 2 ('C' or 'D', i.e. '1' or '0')\n",
    "\n",
    "        Returns:\n",
    "            - tuple of two floats, being the first and second values the payoff\n",
    "            for the first and second player, respectively.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba que los métodos anteriores funcionan correctamente con el siguiente test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints all possible outcomes of the PD\n",
    "pd = Dilemma(2, -1, 3, 0)\n",
    "posible_actions = (C, D)\n",
    "for a1, a2 in itertools.product(posible_actions, repeat=2):\n",
    "    print(f\"{(a1, a2)} -> {pd.evaluate_result(a1, a2)}\")\n",
    "\n",
    "# Output:\n",
    "# (0, 0) -> (2, 2)\n",
    "# (0, 1) -> (-1, 3)\n",
    "# (1, 0) -> (3, -1)\n",
    "# (1, 1) -> (0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El módulo ```player```\n",
    "\n",
    "Ahora vamos a programar una módulo que sirva para representar a los jugadores. En particular, su método principal será ```strategy()```, que devolverá una acción a realizar, en base a la historia de interacción con otro jugador. Además, aprovecharemos a implementar los *jugadores ilustres*, aquellos que juegan estrategias famosas, para que luego sea sencillo hacer pruebas.\n",
    "\n",
    "Empezaremos programando una clase abstracta llamada ```player``` de la que heredarán los jugadores concretos que programaremos a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player(ABC):\n",
    "\n",
    "    # Este método ya está implementado\n",
    "    @abstractmethod\n",
    "    def __init__(self, dilemma: Dilemma, name: str = \"\"):\n",
    "        \"\"\"\n",
    "        Abstract class that represents a generic player\n",
    "\n",
    "        Parameters:\n",
    "            - name (str): the name of the strategy\n",
    "            - dilemma (Dilemma): the dilemma that this player will play\n",
    "        \"\"\"\n",
    "\n",
    "        self.name = name\n",
    "        self.dilemma = dilemma\n",
    "\n",
    "        self.history  = []  # This is the main variable of this class. It is\n",
    "                            # intended to store all the history of actions\n",
    "                            # performed by this player.\n",
    "                            # Example: [C, C, D, D, D] <- So far, the\n",
    "                            # interaction lasts five rounds. In the first one,\n",
    "                            # this player cooperated. In the second, he also\n",
    "                            # cooperated. In the third, he defected. Etc.\n",
    "\n",
    "\n",
    "    # Este método ya está implementado\n",
    "    @abstractmethod\n",
    "    def strategy(self, opponent: Player) -> int:\n",
    "        \"\"\"\n",
    "        Main call of the class. Gives the action for the following round of the\n",
    "        interaction, based on the history\n",
    "\n",
    "        Parameters:\n",
    "            - opponent (Player): is another instance of Player.\n",
    "\n",
    "        Results:\n",
    "            - An integer representing Cooperation (C=0) or Defection (D=1)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def compute_scores(self, opponent: Player) -> tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Compute the scores for a given opponent\n",
    "\n",
    "        Parameters:\n",
    "            - opponent (Player): is another instance of Player.\n",
    "\n",
    "        Results:\n",
    "            - A tuple of two floats, where the first value is the current\n",
    "            player's payoff, and the second value is the opponent's payoff.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    # Este método ya está implementado\n",
    "    def clean_history(self):\n",
    "        \"\"\"Resets the history of the current player\"\"\"\n",
    "        self.history = []\n",
    "\n",
    "\n",
    "# A continuación se representan las 5 estrategias básicas del juego de Nicky Case\n",
    "\n",
    "class Cooperator(Player):\n",
    "\n",
    "    def __init__(self, dilemma: Dilemma, name: str = \"\"):\n",
    "        \"\"\"Cooperator\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def strategy(self, opponent: Player) -> int:\n",
    "        \"\"\"Cooperates always\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Defector(Player):\n",
    "\n",
    "    def __init__(self, dilemma: Dilemma, name: str = \"\"):\n",
    "        \"\"\"Defector\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def strategy(self, opponent: Player) -> int:\n",
    "        \"\"\"Defects always\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Tft(Player):\n",
    "\n",
    "    def __init__(self, dilemma: Dilemma, name: str = \"\"):\n",
    "        \"\"\"Tit-for-tat\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def strategy(self, opponent: Player) -> int:\n",
    "        \"\"\"Cooperates first, then repeat last action of the opponent\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Grudger(Player):\n",
    "\n",
    "    def __init__(self, dilemma: Dilemma, name: str = \"\"):\n",
    "        \"\"\"Grudger\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def strategy(self, opponent: Player) -> int:\n",
    "        \"\"\"\n",
    "        Cooperates always, but if opponent ever defects, it will defect for the\n",
    "        rest of the game\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Detective4MovsTft(Player):\n",
    "\n",
    "    def __init__(self, dilemma: Dilemma, name: str = \"\"):\n",
    "        \"\"\"Four movement - tit for tat detective\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def strategy(self, opponent: Player) -> int:\n",
    "        \"\"\"\n",
    "        Starts with a fixed sequence of actions: [C,D,C,C]. After that, if\n",
    "        the opponent has ever defected, plays 'TFT'. If not, plays 'Defector'.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testearemos este módulo una vez programemos el siguiente\n",
    "\n",
    "#### El módulo ```game```\n",
    "\n",
    "Ya sabemos manejar jugadores. Ahora vamos a enfrentarles. El presente módulo pretende recoger las herramientas necesarias para enfrentar a dos jugadores en una *partida* del dilema del prisionero iterado. Está compuesto por una clase llamada ```Game``` que implementa el método principal ```play()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "\n",
    "    # Este método ya está implementado\n",
    "    def __init__(self, player_1: Player,\n",
    "                       player_2: Player,\n",
    "                       n_rounds: int = 100,\n",
    "                       error: float = 0.0):\n",
    "        \"\"\"\n",
    "        Game class to represent an iterative dilema\n",
    "\n",
    "        Parameters:\n",
    "            - player_1 (Player): first player of the game\n",
    "            - player_2 (Player): second player of the game\n",
    "            - n_rounds (int = 100): number of rounds in the game\n",
    "            - error (float = 0.0): error probability (in base 1)\n",
    "        \"\"\"\n",
    "\n",
    "        assert n_rounds > 0, \"'n_rounds' should be greater than 0\"\n",
    "\n",
    "        self.player_1 = player_1\n",
    "        self.player_2 = player_2\n",
    "        self.n_rounds = n_rounds\n",
    "        self.error = error\n",
    "\n",
    "        self.score = (0.0, 0.0)  # this variable will store the final result of\n",
    "                                 # the game, once the 'play()' function has\n",
    "                                 # been called. The two values of the tuple\n",
    "                                 # correspond to the points scored by the first\n",
    "                                 # and second player, respectively.\n",
    "\n",
    "\n",
    "    def play(self, do_print: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Main call of the class. Play the game.\n",
    "        Stores the final result in 'self.score'\n",
    "\n",
    "        Parameters\n",
    "            - do_print (bool = False): if True, should print the ongoing\n",
    "            results at the end of each round (i.e. print round number, last\n",
    "            actions of both players and ongoing score).\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba que los últimos dos módulos funcionan como se espera en la siguiente celda. Experimenta con distintas combinaciones de jugadores y observa que los resultados son los esperados. Por ejemplo, un Cooperador y un Grudger se pasan toda su interacción cooperando, por lo que en un juego de 10 rondas sin error, ambos deben obtener 20 puntos al final. Comprueba también que el error se está tratando como corresponde. Por ejemplo, fíjalo en un valor alto (e.g. 0.2) y comprueba que en el enfrentamiento de un Cooperador con un Grudger alguno deserta en alguna ocasión. Comprueba también que puedes enfrentar dos jugadores que jueguen la misma estrategia (simplemente crea dos instancias del mismo jugador, con distintos nombres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilemma = Dilemma(2, -1, 3, 0)\n",
    "\n",
    "cooperator_player = Cooperator(dilemma, \"cooperator\")\n",
    "defector_player = Defector(dilemma, \"defector\")\n",
    "tft_player = Tft(dilemma, \"tft\")\n",
    "grudger_player = Grudger(dilemma, \"grudger\")\n",
    "detective_player = Detective4MovsTft(dilemma, \"detective\")\n",
    "\n",
    "#Modifica las siguientes líneas a conveniencia para llevar a cabo distintos tests\n",
    "game = Game(cooperator_player, grudger_player, n_rounds=10, error=0.2)\n",
    "game.play(do_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El módulo ```torunament```\n",
    "\n",
    "Finalmente, llegamos al módulo que nos va a permitir simular el campeonato. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tournament:\n",
    "\n",
    "    # Este método ya está implementado\n",
    "    def __init__(self, players: tuple[Player, ...],\n",
    "                       n_rounds: int = 100,\n",
    "                       error: float = 0.0,\n",
    "                       repetitions: int = 2):\n",
    "        \"\"\"\n",
    "        All-against-all tournament\n",
    "\n",
    "        Parameters:\n",
    "            - players (tuple[Player, ...]): tuple of players that will play the\n",
    "         tournament\n",
    "            - n_rounds (int = 100): number of rounds in the game\n",
    "            - error (float = 0.0): error probability (in base 1)\n",
    "            - repetitions (int = 2): number of games each player plays against\n",
    "         the rest\n",
    "        \"\"\"\n",
    "\n",
    "        self.players = players\n",
    "        self.n_rounds = n_rounds\n",
    "        self.error = error\n",
    "        self.repetitions = repetitions\n",
    "\n",
    "        # This is a key variable of the class. It is intended to store the\n",
    "        # ongoing ranking of the tournament. It is a dictionary whose keys are\n",
    "        # the players in the tournament, and its corresponding values are the\n",
    "        # points obtained in their interactions with each other. In the end, to\n",
    "        # see the winner, it will be enough to sort this dictionary by the\n",
    "        # values.\n",
    "        self.ranking = {player: 0.0 for player in self.players}  # initial vals\n",
    "\n",
    "\n",
    "    def sort_ranking(self) -> None:\n",
    "        \"\"\"Sort the ranking by the value (score)\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    #pista: utiliza 'itertools.combinations' para hacer los cruces\n",
    "    def play(self) -> None:\n",
    "        \"\"\"\n",
    "        Main call of the class. It must simulate the championship and update\n",
    "        the variable 'self.ranking' with the accumulated points obtained by\n",
    "        each player in their interactions.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def plot_results(self):\n",
    "        \"\"\"\n",
    "        Plots a bar chart of the final ranking. On the x-axis should appear\n",
    "        the names of the sorted ranking of players participating in the\n",
    "        tournament. On the y-axis the points obtained.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testear la implementación, por ejemplo prueba a reproducir el campeonato de la sección \"3. One Tournament\" del juego de Nicky Case. En dicho campeonato se enfrentaban las 5 estrategias básicas (cooperador, desertor, tft, grudger y detective) en un torneo con 10 rondas por interacción y sin error. Los resultados que debes obtener son los siguientes:\n",
    " - Tit-For-Tat: ganador con 57 puntos\n",
    " - Grudger: 46 puntos\n",
    " - Detective: 45 puntos\n",
    " - Desertor: 45 puntos\n",
    " - Cooperador: 29 puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilemma = Dilemma(2, -1, 3, 0)\n",
    "\n",
    "cooperator_player = Cooperator(dilemma, \"cooperator\")\n",
    "defector_player = Defector(dilemma, \"defector\")\n",
    "tft_player = Tft(dilemma, \"tft\")\n",
    "grudger_player = Grudger(dilemma, \"grudger\")\n",
    "detective_player = Detective4MovsTft(dilemma, \"detective\")\n",
    "\n",
    "all_players = (cooperator_player, defector_player, tft_player, grudger_player,\n",
    "               detective_player)\n",
    "\n",
    "tournament = Tournament(all_players, n_rounds=10, error=0.0, repetitions=1)\n",
    "tournament.play()\n",
    "tournament.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El módulo ```evolution```\n",
    "\n",
    "Implementa también la variante evolutiva del torneo, similar a la que se explica en la sección \"4. Repeated Tournament\" del juego de Nicky Case. Este módulo necesitará de inputs extra. Ten en cuenta lo siguiente:\n",
    " - La población inicial de jugadores no es directamente el input de jugadores que dé el usuario, sino que cada jugador tiene varios \"individuos\" o \"réplicas\" que jugarán su estrategia. Se propone dar al usuario dos opciones para definir esta población inicial:\n",
    "   - Si el usuario define el tamaño de la población total (```int```), se asume que cada jugador comienza con el mismo número de representantes. Divide ese número entre el número de jugadores (redondeado al entero más próximo) y así obtendrás el número de individuos inicial de cada estrategia.\n",
    "   - Si el usuario define una tupla de números de individuos (```list[int, ...]```), se asume que cada jugador tendrá el número de representantes que indique su índice dentro de dicha tupla.\n",
    " - Hay dos parámetros más que controlan el proceso evolutivo. \n",
    "   - En primer lugar, el porcentaje de individuos que se desea incluir en la selección natural tras cada ronda; esto es, el número de individuos *de la parte de abajo del ranking* que se van a eliminar y sustituir por los *individuos de la parte de arriba* (en caso de empate entre individuos, escoge al azar).\n",
    "   - En segundo lugar, el número de generaciones que se van a simular. Una generación es básicamente un \"Torneo de enfrentamiento directo\" + un \"Proceso de selección natural\". \n",
    "\n",
    "Deberás tomar una decisión sobre qué hacer en la selección natural cuando hay *empates*. \n",
    "\n",
    "A continuación se incluye la plantilla de desarrollo sugerida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evolution:\n",
    "\n",
    "    # Este método ya está implementado\n",
    "    def __init__(self, players: tuple[Player, ...],\n",
    "                       n_rounds: int = 100,\n",
    "                       error: float = 0.0,\n",
    "                       repetitions: int = 2,\n",
    "                       generations: int = 100,\n",
    "                       reproductivity: float = 0.05,\n",
    "                       initial_population: tuple[int, ...] | int = 100):\n",
    "        \"\"\"\n",
    "        Evolutionary tournament\n",
    "\n",
    "        Parameters:\n",
    "            - players (tuple[Player, ...]): tuple of players that will play the\n",
    "         tournament\n",
    "            - n_rounds (int = 100): number of rounds in each game\n",
    "            - error (float = 0.0): error probability (in base 1)\n",
    "            - repetitions (int = 2): number of games each player plays against\n",
    "         the rest\n",
    "            - generations (int = 100): number of generations to simulate\n",
    "            - reproductivity (float = 0.05): ratio (base 1) of worst players\n",
    "         that will be removed and substituted by the top ones in the natural\n",
    "         selection process carried out at the end of each generation\n",
    "            - initial_population (tuple[int, ...] | int = 100): list of\n",
    "         individuals representing each players (same index as 'players' tuple)\n",
    "         OR total population size (int).\n",
    "        \"\"\"\n",
    "\n",
    "        self.players = players\n",
    "        self.n_rounds = n_rounds\n",
    "        self.error = error\n",
    "        self.repetitions = repetitions\n",
    "        self.generations = generations\n",
    "        self.reproductivity = reproductivity\n",
    "\n",
    "        if isinstance(initial_population, int):\n",
    "            self.initial_population = [math.floor(initial_population\n",
    "                                       / len(self.players))\n",
    "                                       for _ in range(len(self.players))]\n",
    "        else:\n",
    "            self.initial_population = initial_population\n",
    "\n",
    "        self.total_population = sum(self.initial_population)\n",
    "        self.repr_int = int(self.total_population * self.reproductivity)\n",
    "\n",
    "        self.ranking = {copy.deepcopy(player): 0.0 for i, player in\n",
    "                        enumerate(self.players)\n",
    "                        for _ in range(self.initial_population[i])}\n",
    "\n",
    "\n",
    "    def natural_selection(self, result_tournament: dict[Player, float]) \\\n",
    "                          -> tuple[list,list]:\n",
    "        \"\"\"\n",
    "        Kill the worst guys, reproduce the top ones. Takes the ranking once a\n",
    "        face-to-face tournament has been played and returns another ranking,\n",
    "        with the evolutionary changes applied\n",
    "\n",
    "        Parameters:\n",
    "            - result_tournament: the 'tournament.ranking' kind of dict.\n",
    "\n",
    "        Results:\n",
    "            - Same kind of dict ranking as the input, but with the evolutionary\n",
    "         dynamics applied\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def count_strategies(self) -> dict[str, int]:\n",
    "        \"\"\"\n",
    "        Counts the number of played alive of each strategy, based on the\n",
    "        initial list of players. Should be computed analyzing the\n",
    "        'self.ranking' variable. Useful for the results plot/print (not needed\n",
    "        for the tournament itself)\n",
    "\n",
    "        Results:\n",
    "            - A dict, containing as values the name of the players and as\n",
    "         values the number of individuals they have now alive in the tournament\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def play(self, do_print: bool = False):\n",
    "        \"\"\"\n",
    "        Main call of the class. Performs the computations to simulate the\n",
    "        evolutionary tournament.\n",
    "\n",
    "        Parameters\n",
    "            - do_print (bool = False): if True, should print the ongoing\n",
    "         results at the end of each generation (i.e. print generation number,\n",
    "         and number of individuals playing each strategy).\n",
    "        \"\"\"\n",
    "\n",
    "        # HINT: Initialise the following variable\n",
    "        #  > count_evolution = {player.name: [val] for player, val in\n",
    "        #                       zip(self.players, self.initial_population)}\n",
    "        # and use it to store the number of individuals each player retains at\n",
    "        # the end of each generation, appending to its corresponding list value\n",
    "        # the number of individuals each player has (obtained by calling\n",
    "        # 'self.count_strategies()'). For example, at some point, it could have\n",
    "        # the following value:\n",
    "        # {'cooperator': [15, 10, 5, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        #  'defector': [5, 10, 15, 19, 14, 9, 4, 0, 0, 0, 0],\n",
    "        #  'tft': [5, 5, 5, 6, 11, 16, 21, 25, 25, 25, 25]}\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # Si quieres obtener un buen gráfico de la evolución, puedes usar este\n",
    "    # método si has seguido la pista indicada en la cabecera del método\n",
    "    # anterior. Ya está implementado, pero puede que necesites adaptarlo a tu\n",
    "    # código.\n",
    "    def stackplot(self, count_evolution: dict[str, list]) -> None:\n",
    "        \"\"\"\n",
    "        Plots a 'stackplot' of the evolution of the tournament\n",
    "\n",
    "        Parameters:\n",
    "            - count_evolution (dict[Player, list]): a dictionary containing as\n",
    "         keys the name of the strategies of the different players of the\n",
    "         tournament. Each value is a list, where the 'i'-th position of that\n",
    "         list indicates the number of individuals that player has at the end of\n",
    "         the 'i'-th generation\n",
    "         \"\"\"\n",
    "\n",
    "        COLORS = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black']\n",
    "\n",
    "        for i, name in enumerate(count_evolution.keys()):\n",
    "            plt.plot([], [], label=name, color= COLORS[(i) % len(COLORS)])\n",
    "\n",
    "        plt.stackplot(list(range(self.generations + 1)),\n",
    "                      np.array(list(count_evolution.values())), colors=COLORS)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testear el módulo anterior, puedes usar alguno de los experimentos mostrados en el juego de Nicky Case. Por ejemplo, un torneo con 5 TFT, 5 Desertores y 15 Cooperantes, sin error, con 10 rondas por interacción, con una reproductividad del 0.2, parece que en menos de 10 generaciones converge a una población dominada por TFT. Intenta replicar este resultado como se muestra a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilemma = Dilemma(2, -1, 3, 0)\n",
    "\n",
    "cooperator_player = Cooperator(dilemma, \"cooperator\")\n",
    "defector_player = Defector(dilemma, \"defector\")\n",
    "tft_player = Tft(dilemma, \"tft\")\n",
    "\n",
    "all_players = (cooperator_player, defector_player, tft_player)\n",
    "\n",
    "evolution = Evolution(all_players, n_rounds=10, error=0.00, repetitions=1,\n",
    "                      generations=10, reproductivity=0.2,\n",
    "                      initial_population=(15, 5, 5))\n",
    "\n",
    "evolution.play(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Enhorabuena! La primera parte de la práctica ya la has terminado. En la siguiente sección, tendrás que diseñar una estrategia para participar en un triple campeonato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: diseño de una estrategia\n",
    "\n",
    "A continuación deberás implementar una estrategia que se enfrentará a las de tus compañeros un un torneo. Antes de describir las condiciones del campeonato, vamos a ver un concepto nuevo. \n",
    "\n",
    "Los juegos contra tus rivales tendrán un final **no determinista**. Esto quiere decir que el número de rondas que se van a jugar no se sabe con precisión. En lugar de eso, después de cada ronda, la partida tiene una cierta probabilidad de acabar (pequeña). ¿Por qué haremos esto? En verdad, el dilema del prisionero con una duración finita es un problema completamente distinto, ya que la proximidad del final de la interacción juega un papel crucial en las decisiones de las estrategias. \n",
    "\n",
    "Con el objetivo de dejar esta complejidad adicional fuera, jugaremos un número de rondas aleatorio: puedes pensar que tu estrategia va a jugar \"muchas veces\" contra cada rival. **En media, se jugarán 100 rondas** (puedes quedarte con ese número). Por supuesto, para que los resultados no estén determinados por el número de rondas jugadas, los puntos obtenidos en cada interacción se normalizarán por el número de rondas jugadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción del campeonato\n",
    "Ahora sí, vamos a ver las condiciones del torneo. Hay tres fases en esta competición:\n",
    " - Fase de enfrentamiento directo entre estrategias\n",
    " - Fase evolutiva\n",
    " - Fase evolutiva dentro del ecosistema completo del DPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Fase de enfrentamiento directo entre estrategias\n",
    "\n",
    "Se jugará un torneo de *todos contra todos*: te enfrentarás a las estrategias de tus rivales dos veces. El resultado que obtengas en cada enfrentamiento se sumará a los ya obtenidos hasta el momento. Ganará la estrategia con más puntos al final de las interacciones. Las condiciones concretas son las siguientes:\n",
    " - El dilema del prisionero que se usará será el siguiente:\n",
    "\n",
    "<center>\n",
    "\n",
    "|      |  C    |  D    |\n",
    "|------|-------|-------|\n",
    "|   C  | 13, 13  | 0, 18  |\n",
    "|   D  | 18, 0  | 4, 4  |\n",
    "\n",
    "</center>\n",
    "\n",
    " - La probabilidad de acabar el enfrentamiento tras cada ronda $P_{end}$ se fija en 1%, con un máximo de rondas de 300.\n",
    " - La probabilidad de error $P_{error}$ se fija en 0.8%.\n",
    " - Se jugará 2 veces contra cada rival.\n",
    "\n",
    "Se asignarán los siguientes puntos según la posición final:\n",
    " - 5º y 6º clasificados: 4 puntos\n",
    " - 4º clasificado: 8 puntos\n",
    " - 3º clasificado: 12 puntos\n",
    " - 2º clasificado: 17 puntos\n",
    " - 1º clasificado: 24 puntos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Fase evolutiva\n",
    "\n",
    "Las estrategias se enfrentarán en un torneo evolutivo, en el que todos parten con el mismo número de representantes. Las condiciones para cada generación son las mismas que en la fase anterior. \n",
    "\n",
    "La reproductividad se manejará de forma ligeramente distinta a lo visto en secciones anteriores. Ahora, en sucesivas generaciones, la proporción de individuos de un jugador frente al total será la misma que la proporción de puntos obtenidos por todos esos individuos frente al total de puntos obtenidos por todas las estrategias. Por ejemplo, imagina que una determinada generación tienes 17 individuos de un total de 100. Estos individuos, en suma han obtenido un total de 210 puntos. Además, la suma de puntos obtenidos por todas las individuos de la población es 1000 puntos. Por tanto, en la siguiente generación dispondrás de 21 individuos.\n",
    "\n",
    "Aquí la evaluación de los ganadores puede ser complicada. En principio, el orden en el que se extingan las estrategias indicará el ranking de esta fase. No obstante, en ocasiones surgen situaciones difíciles de evaluar (por ejemplo, comportamientos cíclicos de dominancia de varias estrategias). En este tipo de escenarios, serán los profesores quienes decidan qué estrategias han sido las más exitosas y su orden. Los puntos que pueden obtenerse en esta fase son los siguientes:\n",
    " - 3º clasificado: 12 puntos\n",
    " - 2º clasificado: 17 puntos\n",
    " - 1º clasificado: 24 puntos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fase evolutiva dentro del ecosistema completo del DPI\n",
    "\n",
    "En esta fase, tu estrategia se enfrentará en un gran torneo evolutivo, donde estarán incluidas las estrategias de tus compañeros, pero también hasta 50 estrategias adicionales del ecosistema del DPI. Estarán las que ya conoces (TFT, Grudger, etc.), y también las estrategias que se han mostrado más exitosas en las últimas publicaciones científicas. De nuevo, el criterio general para establecer el ranking entre nuestras estrategias será: \"cuanto más tarde se extingan tus individuos, más alto estarás en el ranking\". Al haber tantas estrategias involucradas, esta parte del campeonato es la más susceptible a presentar situaciones difíciles de evaluar, por lo que en última instancia serán los profesores quienes, partiendo de criterios objetivos, seleccionen las tres estrategias más exitosas, que se llevarán:\n",
    " - 3º clasificado: 4 puntos\n",
    " - 2º clasificado: 8 puntos\n",
    " - 1º clasificado: 12 puntos\n",
    "\n",
    "Los puntos de las tres fases se sumarán y **el grupo ganador obtendrá 0.4 puntos extra en la evaluación de la asignatura**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación de tu estrategia\n",
    "\n",
    "A la hora de implementar tu estrategia ten en cuenta lo siguiente:\n",
    " - Si has seguido la plantilla de desarrollo de la primera parte de la práctica, tu estrategia deberá ser implementada como un subclase de la clase abstracta ```Player()```. En particular, debes implementar cuidadosamente su método ```strategy()```. \n",
    " - No olvides darle un buen nombre a tu estrategia. \n",
    " - Igualmente, mientras implementas, incluye todo los comentarios que puedan ayudar a los profesores a evaluar positivamente tu estrategia. Por ejemplo: \"*he visto que mi estrategia funcionaba mal contra Desertores, por eso incluyo el siguiente bloque de código que pretende...*\". \n",
    " - **¡IMPORTANTE!** Incluye información suficientemente extensa para explicar tus decisiones de diseño, por qué presentas esa estrategia y no otra, cuáles son los resultados que has observado en las pruebas que has hecho, qué problemas te has encontrado y cómo los has solucionado, etc.\n",
    "\n",
    "A continuación se incluye un ejemplo de implementación de una estrategia. De hecho, este ejemplo será la estrategia de los profesores, ¡y participará en el campeonato! Así que ya sabes una de las estrategias que va a estar presente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Destructomatic(Player):\n",
    "\n",
    "    def __init__(self, dilemma: Dilemma, name: str = \"\"):\n",
    "        super().__init__(dilemma, name)\n",
    "        self.defection_count = 0\n",
    "        self.consecutive_cooperation = 0\n",
    "        self.rounds_to_defect = 0\n",
    "\n",
    "    def strategy(self, opponent: Player) -> int:\n",
    "        \"\"\"\n",
    "        A gradual forgiveness strategy.\n",
    "        Starts cooperating, increases defection periods for repeated defections,\n",
    "        and resets after a series of cooperations.\n",
    "        \"\"\"\n",
    "\n",
    "        turns = len(self.history)\n",
    "\n",
    "        if turns == 0:  # First move, always cooperate\n",
    "            return C\n",
    "\n",
    "        if self.rounds_to_defect > 0:\n",
    "            self.rounds_to_defect -= 1\n",
    "            return D  # Defect if we're in a defection period\n",
    "\n",
    "        last_move = opponent.history[-1]\n",
    "\n",
    "        if last_move == C:\n",
    "            self.consecutive_cooperation += 1\n",
    "            if self.consecutive_cooperation >= 5:\n",
    "                self.defection_count = 0\n",
    "                self.consecutive_cooperation = 0\n",
    "        else:  # Opponent defected\n",
    "            self.defection_count += 1\n",
    "            self.consecutive_cooperation = 0\n",
    "            self.rounds_to_defect = self.defection_count\n",
    "            return D  # Defect immediately after opponent's defection\n",
    "\n",
    "        return C  # Cooperate otherwise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Espacio para el desarrollo de tu estrategia\n",
    "\n",
    "Implementa tu estrategia en la plantilla de la siguiente celda, modificándola a conveniencia. Puedes añadir más métodos si lo necesitas. Incluye una descripción explicando el proceso que has seguido para diseñarla: usa el docstring de tu clase o una celda de texto adicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NombreDeTuEstrategia(Player):\n",
    "\n",
    "    def __init__(self, dilemma: Dilemma, name: str = \"\"):\n",
    "        \"\"\"\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def strategy(self, opponent: Player) -> int:\n",
    "        \"\"\"\"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la entrega, explica en detalle el proceso de diseño de tu estrategía, por qué has decidido presentar esa estrategia y no otras con las que hayas probado, qué consideraciones has tenido en cuenta al diseñarla, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haz todas las pruebas que necesites aquí.\n",
    "# Por ejemplo:\n",
    "#\n",
    "# game = Game(Destructomatic(dilemma, \"destr\"), Tft(dilemma, \"tft\"),\n",
    "#             dilemma, n_rounds=10, error=0.1)\n",
    "# game.play(do_print=True)\n",
    "#\n",
    "# O también:\n",
    "#\n",
    "# dilemma = Dilemma(13, 0, 20, 4)\n",
    "# participants = (Destructomatic(dilemma, \"destr\"),\n",
    "#                 Cooperator(dilemma, \"coop1\"),\n",
    "#                 Defector(dilemma, \"defect\"),\n",
    "#                 Cooperator(dilemma, \"coop2\"),\n",
    "#                 Tft(dilemma, \"tft\"),\n",
    "#                 Detective4MovsTFT(dilemma, \"detect\"))\n",
    "#\n",
    "# tournament = Tournament(participants, dilemma, n_rounds=100, error=0.01,\n",
    "#                         repetitions=2)\n",
    "# tournament.play()\n",
    "# tournament.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Rúbrica de calificación de la práctica\n",
    "\n",
    "PARTE 1:\n",
    " - **[4/10] Funcionamiento del código**: el código descrito en la *Parte 1* de la práctica debe funcionar correctamente, sin *bugs*, permitiendo reproducir todas las funcionalidades descritas.\n",
    " - **[2/10] Limpieza y claridad de estilo**: el código debe estar bien escrito, siguiendo la guía de estilo PEP 8. \n",
    "  \n",
    "PARTE 2:\n",
    " - **[1/10] Implementación de una estrategia correcta**: que funcione sin errores y que esté programada con claridad.\n",
    " - **[3/10] Originalidad de la estrategia y trabajo de exploración llevado a cabo**: el tipo de estrategia presentada, junto con las explicaciones que hayas aportado en comentarios y demás, pondrá de manifiesto el trabajo de experimentación que has llevado a cabo con tu estrategia. Este item pretende evaluar este aspecto.\n",
    "  \n",
    "EXTRAS: \n",
    " - **[1.5 puntos] extras al ganador del campeonato**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1beef6bdf7cb3edc825034b485381c9781f3bd7bbda8256bc912318d884443a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
